{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommendation System\n",
    "\n",
    "In this Jupyter Notebook, we are building a movie recommendation system based on plot similarity. The workflow involves the following steps:\n",
    "\n",
    "1. **Importing Libraries**: We import necessary libraries such as `pandas` for data manipulation, `numpy` for numerical operations, and `sklearn` for machine learning utilities.\n",
    "\n",
    "2. **Loading Data**: We load the movie dataset from a CSV file (`tmdb_5000_movies.csv`) and select only the required columns (`id`, `title`, `overview`). We also handle missing values by dropping rows with missing overviews.\n",
    "\n",
    "3. **Text Vectorization**: We use `TfidfVectorizer` from `sklearn` to convert the movie overviews into a TF-IDF matrix. This matrix represents the importance of words in each overview while reducing the impact of common words (stop words).\n",
    "\n",
    "4. **Cosine Similarity Calculation**: We compute the cosine similarity matrix from the TF-IDF matrix. This matrix helps in measuring the similarity between different movie overviews.\n",
    "\n",
    "5. **Recommendation Function**: We define a function `get_recommendations` that takes a movie title as input and returns the top 10 recommended movies based on plot similarity. The function uses the cosine similarity matrix to find similar movies and applies the softmax function to convert similarity scores into likelihood percentages.\n",
    "\n",
    "6. **Testing the Recommendation System**: We test the recommendation function with an example movie title (\"The Shawshank Redemption\") to see the top recommended movies and their similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess the Movie Dataset\n",
    "\n",
    "In this cell we read the movie dataset from the CSV file `tmdb_5000_movies.csv` and select only the essential columns: **id**, **title**, and **overview**.  \n",
    "We then drop any rows where the **overview** is missing to prevent issues during the vectorisation stage. Finally, we display the first few rows of the cleaned dataset to verify that the data has been loaded correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>Avatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206647</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>Spectre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49026</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49529</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>John Carter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           overview  \\\n",
       "0   19995  In the 22nd century, a paraplegic Marine is di...   \n",
       "1     285  Captain Barbossa, long believed to be dead, ha...   \n",
       "2  206647  A cryptic message from Bond’s past sends him o...   \n",
       "3   49026  Following the death of District Attorney Harve...   \n",
       "4   49529  John Carter is a war-weary, former military ca...   \n",
       "\n",
       "                                      title  \n",
       "0                                    Avatar  \n",
       "1  Pirates of the Caribbean: At World's End  \n",
       "2                                   Spectre  \n",
       "3                     The Dark Knight Rises  \n",
       "4                               John Carter  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the CSV file path\n",
    "csv_file_path = 'tmdb_5000_movies.csv'  # Replace with your actual file path\n",
    "\n",
    "# Read the CSV file while selecting only the required columns\n",
    "df = pd.read_csv(csv_file_path, usecols=['id', 'title', 'overview'])\n",
    "\n",
    "# Optionally drop rows with missing overviews to avoid errors during vectorisation\n",
    "df.dropna(subset=['overview'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the first few rows to verify the correct columns are loaded\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation and Similarity Computation\n",
    "\n",
    "In this cell we initialise a `TfidfVectoriser` with English stop words to convert the text in the **overview** column into a TF‑IDF matrix.  \n",
    "This matrix represents the importance of each word in the context of the entire dataset.  \n",
    "We then compute the cosine similarity matrix from the TF‑IDF matrix, which quantifies how similar each pair of movie overviews is.  \n",
    "This similarity matrix is a key component of our plot‐based recommendation system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the TfidfVectoriser using English stop words\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the 'overview' column into a TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(df['overview'])\n",
    "\n",
    "# Compute cosine similarity matrix from the TF-IDF matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Recommendation Functions\n",
    "\n",
    "In this cell we define two key functions:\n",
    "\n",
    "1. **softmax(x):**  \n",
    "   This function applies the softmax transformation to the input array `x`. It normalises the cosine similarity scores so that they form a probability distribution, which is then multiplied by 100 to represent the values as percentages.\n",
    "\n",
    "2. **get_recommendations(title, cosine_sim=cosine_sim):**  \n",
    "   This function retrieves and displays the top 10 recommended movies based on plot similarity. It performs the following steps:\n",
    "   - **Index Retrieval:** Finds the index of the specified movie title in the dataset.\n",
    "   - **Score Computation:** Enumerates and sorts the cosine similarity scores in descending order, excluding the movie itself.\n",
    "   - **Likelihood Calculation:** Converts the similarity scores into percentage likelihoods using the softmax function.\n",
    "   - **Output:** Prints a neatly formatted table showing each recommended movie, its similarity score, and its likelihood percentage, and returns these values as a tuple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    \"\"\"\n",
    "    Given a movie title, return the top recommendations based on plot similarity,\n",
    "    print each recommended movie with its similarity score,\n",
    "    and show a \"likelihood\" (converted cosine similarities using softmax).\n",
    "\n",
    "    Parameters:\n",
    "        title (str): The title of the movie.\n",
    "        cosine_sim (ndarray): Precomputed cosine similarity matrix.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing a list of recommended movie titles and a list of corresponding (index, score) pairs.\n",
    "    \"\"\"\n",
    "    # Retrieve the index for the movie that matches the title\n",
    "    idx = indices.get(title)\n",
    "    \n",
    "    if idx is None:\n",
    "        print(f\"Title '{title}' not found in dataset.\")\n",
    "        return [], []\n",
    "    \n",
    "    # Enumerate over similarity scores and sort in descending order\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Exclude the movie itself and take the top 10 recommendations\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Retrieve the recommended movie titles\n",
    "    recommended_titles = df['title'].iloc[movie_indices].tolist()\n",
    "    \n",
    "    # Convert similarity scores to likelihoods using softmax\n",
    "    scores = np.array([score for _, score in sim_scores])\n",
    "    likelihoods = softmax(scores) * 100  # convert to percentage\n",
    "    \n",
    "    # Print the results in a neat table\n",
    "    print(\"Top 10 Recommendations:\")\n",
    "    print(\"{:<30} {:>10} {:>15}\".format(\"Movie Title\", \"Score\", \"Likelihood (%)\"))\n",
    "    print(\"-\" * 60)\n",
    "    for rec_title, (_, score), likelihood in zip(recommended_titles, sim_scores, likelihoods):\n",
    "        print(\"{:<30} {:>10.4f} {:>15.2f}\".format(rec_title, score, likelihood))\n",
    "    \n",
    "    return recommended_titles, sim_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Mapping and Test the Recommendation Function\n",
    "\n",
    "In this cell we create a dictionary that maps movie titles to their corresponding indices in the DataFrame.  \n",
    "This mapping is essential for quickly retrieving the index of a movie when running our recommendation function.  \n",
    "We then test the recommendation system using an example title (\"The Shawshank Redemption\").  \n",
    "If this title is not present in your dataset, please replace it with one that exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommendations:\n",
      "Movie Title                         Score  Likelihood (%)\n",
      "------------------------------------------------------------\n",
      "Civil Brand                        0.1884           10.74\n",
      "Prison                             0.1334           10.17\n",
      "Escape Plan                        0.1314           10.15\n",
      "Fortress                           0.1140            9.97\n",
      "Penitentiary                       0.1084            9.92\n",
      "The 40 Year Old Virgin             0.1079            9.91\n",
      "Fatal Attraction                   0.0990            9.83\n",
      "A Christmas Story                  0.0944            9.78\n",
      "The Longest Yard                   0.0928            9.77\n",
      "Toy Story 3                        0.0920            9.76\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from movie titles to their indices\n",
    "indices = pd.Series(df.index, index=df['title']).to_dict()\n",
    "\n",
    "# Test the recommendation function with an example title\n",
    "example_title = \"The Shawshank Redemption\"  # Replace with an actual title from your dataset\n",
    "recommendations, sscores = get_recommendations(example_title)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
